---
title: "Boostcamp AI Tech (Day 028)"
date: 2024-09-11
layout: post
tags: [Naver Boostcamp, daily report]
---
## 1. 강의
<!-- 5강 듣고  -->

## 2. 피어세션
- 브랜치 머지
- 무조건적인 어그멘테이션이 좋은 건 아니다
- 랜덤시드 고정 
- ipynb -> py로 변경
- 정확도랑 로스는 에폭마다 확인하고 최종값에 F1스코어확인
- 장기자랑
- save model을 하는 이유 : 에폭 다 돌고나서 무조건 이게 최상의 상태가 아님. 에폭 돌다가 중간 어딘가에 잘 되었을 그 때의 상태를 저장해야함!!
- 트레이너.py를 만들어야겠다
- 데이터로더가 텐서를 얻는건데
데이터셋 : 파일을 불러서 겟아이템 함수 정의해. 그래서 하나씩 뽑아. 데이터가 들어잇는거
데이터로더 : 데이너셋 클래스 객체를 받아서 원하는대로 뽑는거!. 셔플, 배치사이즈별로 뽑기 등
- 돌려보기 시도

## 3. 회고
- 지각 즐겁다~~
- 팀플 즐겁다!!!
- 멘토링이 참 많은 걸 고민하게 한다
- 직접 짜니까 사람된 거 같아서 기분 좋다

## 4. 멘토링
멘토링
- 첫 경험이니까 모델 구현뿐아니라 뭐 서버 이용이나 이런 거 배우기? 가 목표입니다
이번 프젝 안에 ... 깃헙 기여도 3위안에 들기엿는데 안보이더라 지금
문서작업을 열심히하겟다 모델 가져올때 이거 왜 가져왓는지... 이런거
우리 프젝에서 써잇을 위키에 다... 알고잇기
하나의 프로세스를 내가 한번 빠르게 해보겟다! 면 모델 하나하나뜯어보기랑 안맞긴 하다
누가 우리꺼볼때 이거 왜썼어???하면 바로바로 나오도록
원랜 모든 프로세스를 대강 파악하는 거엿늗데 
이건 당연한거긴 함...
테크니컬한 부분이 필요하다. 최적화랑 스케줄러 맡아보심 어덜까! 굳
아담. sgd with모멘텀 등 말고도 나담 롸담 많음... 이걸 좀 뭐가잇는지 조사하고 딴사람이 돌렷던 실험에 옵티마이즈 바꿔서 해봐도 좋고
스케줄러 러닝레잇을 선형적으로 줄익고나 코사인으로 되거나 많으니까 이건 움 해봐!!! 알아보고 해봐!!! 

- 고정된 데이터만 학습하는거보단 트랜스폼하는게 굳이다.
- 온라인어그멘테이션 (돌아가는중에 변함. 메모리 적게씀) 여튼 ㅇㅇ
- 그레이스케일을 rgb로 맞춰라 이미지 자체가 1차원이면 3배로 복제하고 아니면 뭐 확인해라
- 아웃라이어가 치명적이면 버리고... 

- 보통 albumentation 많이 쓴다 페이스북의 어글리?도 많이 쓴다 
- 마스킹 등 뭐 멀 조합해서 뭐 하게다고할거면 좀 정리를 해놔야할거다... 지금은 늦었음
- 랜덤시드 고정이 트레인의 가장 첫번째. 머신 4개쓸거니까... 이미 4번 달라지자나....? 동일한 환경에서 실행할 수 있도로 ㄱ해야함..
- 현실적으로 토치비전에 트랜스폼은 예시로만 씀... 앨버멘테이션으로 변경
- 데이터 인덱스를 처리해라... 셔플은 로더에선 false로 놓고...
- k폴드 해라 5개혹은 10개정도의 청크를 나눠놔라
- 이제 test 셋은 없다... validation은 있지만
- 배깅과 부스팅을 찾아봐라
- k폴드는 하나의 모델을 k번 훈련시키는 것임
장점 : 데이터를 최대한 활용
단점 : 시간 많이 듬
우리 데이터30밖에없는데 
데이터훈련되지않은 가중치로 제출할건지
실험자의 감에 의해... 제출용은 val데이터까지넣고 에폭 적당히줘서...했는데
이럼이제 오버피팅이슈가 감으로? 지.
이제 어찌하냐면 트릭인데
만약 9:1로 훈련시켜. 이때 정확도가 80 100이 나왓어
굉장히 좋은 초기값이 나왔당
이제 마지막 1-2에폭정도는 1:9로 돌려봐
이때 정확도가 100 80이 아니라 100은 유지되고 80은 더 올라가면 
아 일반화성능 유지되는 수준이구나 지금!! 하는 것임
=> 모델이 아직 경험하지 않은 데이터가 남아있는데 제출하는 건 횟수 낭비다
=> 만약 데이터 안 본 애가 더 성능이 좋다? 모델훈련방식이 잘못된거임...

- utils 라고 쓰면 토치.utils랑 겹치므로 util이라고 써라
- 데이터로더.py말고 data.py에 커스텀데이터클래스가 있고 여기에 함수로 커스텀 데이터 로더를 넣어서 트레인에서호출할때 train_ = 겟데이터로더. 이런식으로 호출을 함
-  wandb 에 다찍으면 좋음 러닝레잇, 클래스별 로스, 밸루데이션로스, 클래스별 어큐러씨, 밸루 어큐러씨. 지금처럼 데이터가 적은 경우엔 틀린 애들의 인덱스를 모아서 그 그림들을 뽑아와도 ㄱㅊ을듯
이제 많은 문제에서 어큐러씨만 쓰는 시대는 지낫으니 F1스코어도 찍어보면 좋을듯
- 훈련에 문제는 많이 없겠지만, 보통 train_loss = trainloss/len(dataset) 안함. 배치개수로 나누면 어쩌니. 실제 처리한 데이터 개수로 나누는게 좋음. 600개랑 601개랑 배치개수 6 7 이 되어 뭐가 이상하잖아. droplast = True를 두면 1개 날리니까 ㄱㅊ음 근데 데이터 적으면 그건 또 아깝지
- modal.evel() 이랑 model.train() 써줘야함
- 만약 큰 데이터 다루면 매 에폭마다 벨루데이션 계산하는건 의미 없음.
트레인 로스나 그게 개선됐을때 벨루데이션이 높아지는걸 봐야 의미잇지... 
트레인이나 이게 개선됏을때 밸루데이션 하는것도 전략.
- 실험관리 뭘로 하는지 음 엑셀로 하신대요 노션이나 스프레드시트 테이블써도 ~~
- 실험자, 시드넘버, 뭐 이미지 사이즈도 커스텀할거면 쓰고?, 모델에대한 구체적인정보(resnet18, pretrain뭐썼는지...), 트랜스퍼러닝ㅇ했으면 프리징을 어디까지 했는지, 프리트레인은 피처 뽑는거밖에 못하잖아? 그 뒤에 클래스든 바뀔텐데 mlp를 썼나? 뭘썻나. 뭐 어디까지 고정하고 뒤에 레이블 몇 개를 더 쌓았는지. 그 레이블쌓은거는 뭘로 초기화했는지, 배치사이즈ㅡ, 스케줄러, 옵티마이즈, 본인의 짧은 의견 ( mlp레이어 4층이상 쌓으면 안좋음. )+ 훈련할때사용되는 메모리양? v100이면 뭐 32기가? 만약 이 모델이 12ㅉ빠리면 좀 늦겠지만 12 두 개 올려야 좋음, 최소 몇 에폭은 훈련해야겟더라. 
- 여러 모델 마지막에 나올테니 앙상블 해봐야겟지? 하드보팅과 소프트보팅?부팅? 하드: 각모델이 독같은 가중치를 갖는다. 소프트 : 지표하나정하고 걔를 곱해줘서 가중치 좀 다르게~! 
- 우리가 학습하는데 모델 자체가 틀린데이터가 분명 존재함 여러모델이 똑같이 틀리는 이런애가 
벨루데이션셋을 랜덤하게 짜는게 정답아닐수있음. 밸루데이션을 잘 짜야함... 사람이봐도 어려운걸 넣으면 우짬... 얘를 맞출만큼 일반화성능 좋은 모델을 찾늑 게 좋을거고...
암튼 난이도에관계없이 모델이 잘 되는... 웅
데이터가 개많으면. 파운데이션모ㅗ델ㅇ같은건 랜덤 벨루데이션 ㄱㅊ은데 지금은 아니잖아?? 아님 뭐 어려운거훈련시켯더니 쉬운거 잘 풀어? 기특 복복복복함 되고
- 일단 주피터노트북파일은 실험끝났다고 알려주지안잖아? ㅇ이건 간단한 내 아이디어 검증용이고 실제 거대 트레인은 파이썬 스크립트 파일. 이어야함.
아 이미지 뭐 하나 넣어봐야?하ㅣㄹ떼 ㅆ,ㄴ데
py여야 뭐 끝나고 뭐... 자동화얘긴가
- 하이퍼파라미터 옵티마이제이션 그레이튠? 완디비의 스윗? 스윕? 적당한거 넣어두면 하이퍼파라미터 ㄱㅊ게 찾아줌
- 어떤 모델을 어떻게 구현할것인가. 를 하고 싶으면 모듈 몇 개 정해서 구현해놔야지? 더 나아가서 cnn 5층!이면 컨벌루션 5번 하는 자동 생성하는. 모델 구현하든가 그런
- 액티베이션s 파일 불필요하지... 내가 구현해야할 액티베이션 펑션이 있으면 쓰고 없으면 대체 왜...ㅋㅎ 아니그리고 액티베이션 펑션 우리가 구현 안 함... 거의 보통
- 체크포인트 : 토치 닷 세이브쓰지말고 스테이이딕트 아님? 모듈 지금 쓰는 게 뭔지 확인해보시길 아 아니구나 ㄱㅊ대요
- 요즘은 파이썬 개발자들이 개발을 못 함... 동적타이핑땜에! 그래서 요즘은 타입을 미리 지정해두는,,, 타입힌트를 지원하는 형태로 많이 개발 됨
- 이정도하면 개발 준비 완...
- 헬퍼스인코드? 엥 여기에 우리가 활용하는 어 뭐 데이터셋 적어도 나오니까 여기서 높은 점수 나오는 거 찾아다가... 적용해봐라

## 5. 마스터클래스
- 실제 현업에서 ai 모델 개발 관련
- 문제 정의를 해야 함.
- 기본적인 내용이 필요. 이미지라는 데이터를 생각해서 넣어야함! 어차피딥러닝이알아서?라고 하면 안됨!!
- 막연한 과정으로 막연한 결론내면 막연한 경험이 됨...
- 기초대회 강의는 쉽지만 실습느낌으로다가 하나의 프로세스를 경험해봐라 : competition Problem Definition - Image Data Image Precessing - Model & Inductive Bias Representation - Training Process - Metric Ensemble - Experiments
- 잘하는 사람이 많은데 내가 제일 못 함 헉 나잖아~?? 
- 찾아서 해라
- 보통 지식은 출처가 있음 내가번뜩일수도... 여튼 지식의 주인이 되어라 그게 모이면 연결됨 이 대회에서 얻어가라
- 지금의 리더보드는 정말 노상관
- 모델을 블랙박스로 이해하지 마라
- 김태진 마스터님은 어려운 분이 아니니 디엠 주든 소환해도 괜찮으시대
- 잠수타지않는 게 가장 중요하대
- 협력에서 잘해야한다보다 소외될 필요 없다. 가 중요함
- 공기업, 은행, 사진부터 요구하는 곳이면 복장 신경 쓰겠지만... 회사바이회사 면접복장 맞추기
- 학생을 평가할 때 (경력이런 게 없으니) 학업에 대한 얘길 할 수밖에 cs지식 등 다다익선, 계속 추구해나가는 과정에서 지식을 이렇게 말해야하나 배우고, 면접은 소개팅이다
- 면접 해보면 힌트가 얻어진다. 인재상 등
- ai로 해결해야하나? 했는데 ai로 해결 안 했을 때 좀 즐거움 적재적소에 엔지니어링을 하는 게 엔지니어링의 즐거움이다