---
title: "Boostcamp AI Tech (Day 004)"
date: 2024-08-08
layout: post
tags: [Naver Boostcamp, daily report]
---
## 1. 마스터 클래스 (오영석 마스터님)
### 담론의 정의
동일한 형성의 계열에 속하는 언표들의 집합 (Foucault, 2000).
- 동일한 형성의 계열: 특정한 시대나 문화적 맥락에서 지식이 일정한 규칙을 가지고 형성되는 방식
  - 예시: 정치학, 경제학, 법학, 물리학, 수학 등

### 언어와 사고의 관계
- "언어 자체가 곧 사고(언어=사고)" (Vygotsky, 2011)
  - 이러한 이유에서 LLM의 성공은 당연한 예견이었음
  - 하지만 아직까지 갈 길은 멀다!
    - 자연어로 완벽한 소통은 아직 어려우며, 프롬프트 엔지니어링이 필요한 이유이기도 함

### 학제간 담론의 정의
- ‘학제간’이란 여러 학문 분야가 협력하여 연구하거나 문제를 해결하는 방식을 의미함

### 인공지능 담론에서 수학적 담론이 중요한 이유
- 인공지능 담론에서 수학적 담론 위치는 절대적임
  - 복잡한 문제를 해결할 수 있는 알고리즘을 제공함

## 1-1. 인공지능 시대를 여는 학제간 담론
### 인공지능 시대를 여는 학제간 담론의 필요성
- 기호주의 AI 패러다임에서 AI는 컴퓨터 엔지니어링의 한 분야에 불과했음
- 머신러닝 패러다임으로 전환됨에 따라 데이터가 중요해짐
  - 데이터는 도메인의 가장 기초적이면서 핵심이 되는 요소임
    - AI와 도메인 사이의 융합의 가능성
- 사실상 AI가 범용 기술임에도 불구하고, 융합의 가능성에 대한 회의적인 시선이 있음 (AI 거품론 등)
- 그러므로, AI와 다양한 도메인을 융합함으로써 학제간 담론을 확장할 필요가 있음

### Add-value할 수 있는 어플리케이션
- 여러 가지 담론을 토대로 함께 협력하여 우리의 일상을 Add-value할 수 있는 어플리케이션 개발
  - 어플리케이션 개발의 필요성, 중요성, 개발 방법 구체화

## 1-2. PyTorch 강좌 120% 활용하기
### 조교님들과 소통하기
- PyTorch 강좌를 위해 모이신 국내 산학계에서 뛰어난 조교님들
  - 국내 최고의 기업에서 AI Researcher, AI 스타트업 기업 이사 경험이 있으신 조교님
  - 국내 최고의 대학에서 연구하고 계신 조교님
  - Kaggle, 해커톤 대회 등에서 우승 경험이 있으신 조교님
- PyTorch 강좌 및 과제 관련 질문과 더불어 산학계와 관련하여 많은 질문들을 하시며 소통하기.

### 강좌를 수강함에 있어서 완벽주의보다는 목표 달성주의로
- 캠퍼분들께서 PyTorch 강좌의 목표를 달성하실 수 있도록 이론 내용을 반복한 실습 영상을 제공해주셨다.
- 만약 완벽주의 또는 첫 주의 바쁜 일정으로 인하여 지금까지도 강의 진도가 더디시다면, 과감하게 실습 영상부터 학습하고, 실습 영상이 이해가지 않을 경우에 이론 학습을 추천하신다.
- 그리고 기본 과제 및 심화 과제를 꼭 해결하시고 조교님들과 소통하는 시간을 가지셨으면 한다.

### 각각의 표현들을 심도 있게 살펴보기
- 각각의 언어적 표현, 수학적 표현, 코드 표현들은 학제간 담론의 대상들이다.
  - 따라서 각각의 표현들은 가족 유사성을 가진다.
- 이러한 부분을 고려해서 각각의 표현들을 다시 한 번 정리하시기 바란다.

## 2. assignment#2 풀이
저는 코드를 리팩터링하고 주석과 설명을 더해서 풀이과정을 정리했습니다.

### 문제 1: 데이터셋 이해 및 전처리

우선 데이터셋을 불러오고 전처리하는 과정입니다. 이 데이터는 자동차 구매 여부를 결정하는 요소들을 포함하고 있습니다. 주요 변수로는 `User ID`, `Gender`, `Age`, `EstimatedSalary`, 그리고 `Purchased`가 있습니다. 여기서 `User ID`는 모델 학습에 필요하지 않으므로 제거하고, `Gender`는 숫자형으로 변환합니다. 또한, `Age`와 `EstimatedSalary`는 표준화를 통해 정규화해줍니다.

#### 코드:
```python
import pandas as pd
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split

# 데이터셋 불러오기
data = pd.read_csv("car_data.csv")

# 불필요한 열 제거
X = data.drop(columns=['User ID', 'Purchased'])
y = data['Purchased']

# 성별을 숫자로 변환 (Male=0, Female=1)
X['Gender'] = X['Gender'].apply(lambda x: 0 if x == "Male" else 1)

# 나이와 연봉을 표준화
scaler = StandardScaler()
X[['Age', 'EstimatedSalary']] = scaler.fit_transform(X[['Age', 'EstimatedSalary']])

# 학습용과 테스트용 데이터로 분할
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
```

### 문제 2: PyTorch Dataset 클래스 작성

PyTorch에서 데이터셋을 다루기 위해 `Dataset` 클래스를 상속받아 새로운 클래스를 정의합니다. 이 클래스는 데이터셋의 크기를 반환하는 `__len__` 메서드와 특정 인덱스의 데이터를 반환하는 `__getitem__` 메서드를 구현합니다.

#### 코드:
```python
import torch
from torch.utils.data import Dataset

class CarPurchaseDataset(Dataset):
    def __init__(self, X, y):
        self.X = torch.tensor(X.values, dtype=torch.float32)
        self.y = torch.tensor(y.values, dtype=torch.float32).view(-1, 1)
        
    def __len__(self):
        return len(self.X)
    
    def __getitem__(self, idx):
        return self.X[idx], self.y[idx]
```

### 문제 3: 로지스틱 회귀 모델 구현 및 학습

로지스틱 회귀 모델을 PyTorch로 구현합니다. 모델은 선형 변환을 적용한 후 시그모이드 함수로 이진 분류 확률을 계산합니다.

#### 코드:
```python
import torch.nn as nn

class LogisticRegressionModel(nn.Module):
    def __init__(self, input_dim):
        super(LogisticRegressionModel, self).__init__()
        self.linear = nn.Linear(input_dim, 1)
    
    def forward(self, x):
        return torch.sigmoid(self.linear(x))

# 입력 데이터 차원 설정
input_dim = X_train.shape[1]  # 3개 입력 변수 (Gender, Age, EstimatedSalary)
model = LogisticRegressionModel(input_dim)
```

### 문제 4: 손실 함수와 옵티마이저 설정

모델을 학습시키기 위해 손실 함수와 옵티마이저를 설정합니다. 손실 함수로는 `BCELoss`를 사용하며, 옵티마이저로는 `SGD`를 사용합니다.

#### 코드:
```python
import torch.optim as optim

criterion = nn.BCELoss()
optimizer = optim.SGD(model.parameters(), lr=0.01)
```

### 문제 5: 모델 학습 함수 작성

모델을 학습하는 함수를 작성합니다. 이 함수는 학습 데이터셋을 여러 번 반복하여 모델이 최적화되도록 합니다.

#### 코드:
```python
def train_model(model, criterion, optimizer, dataloader, device, num_epochs=100):
    model.to(device)
    for epoch in range(num_epochs):
        model.train()
        total_loss = 0
        for inputs, labels in dataloader:
            inputs, labels = inputs.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss/len(dataloader):.4f}")

# 데이터 로더 생성
train_dataset = CarPurchaseDataset(X_train, y_train)
train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=32, shuffle=True)

# GPU가 있으면 GPU로, 아니면 CPU로 설정
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# 모델 학습
train_model(model, criterion, optimizer, train_loader, device, num_epochs=100)
```

### 문제 6: 모델 평가 함수 작성

모델이 학습된 후, 테스트 데이터셋을 이용하여 모델의 성능을 평가합니다. 성능은 정확도로 측정합니다.

#### 코드:
```python
def evaluate_model(model, dataloader, device):
    model.eval()
    correct = 0
    total = 0
    with torch.no_grad():
        for inputs, labels in dataloader:
            inputs, labels = inputs.to(device), labels.to(device)
            outputs = model(inputs)
            predicted = (outputs >= 0.5).float()
            correct += (predicted == labels).sum().item()
            total += labels.size(0)
    accuracy = correct / total
    print(f"Accuracy: {accuracy:.4f}")

# 테스트 데이터 로더 생성
test_dataset = CarPurchaseDataset(X_test, y_test)
test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=64, shuffle=False)

# 모델 평가
evaluate_model(model, test_loader, device)
```

### 문제 7: 통계적 방법으로 모델 학습 및 비교

`statsmodels`를 이용하여 통계적 방법으로 로지스틱 회귀 모델을 학습시키고, PyTorch 모델과 성능을 비교합니다.

#### 코드:
```python
import statsmodels.api as sm

# 통계 모델에 맞게 데이터 준비
X_train_sm = sm.add_constant(X_train)
logit_model = sm.Logit(y_train, X_train_sm)
result = logit_model.fit()

# 모델 요약 출력
print(result.summary())

# 통계 모델로 예측
X_test_sm = sm.add_constant(X_test)
y_pred_sm = result.predict(X_test_sm)
y_pred_class_sm = (y_pred_sm >= 0.5).astype(int)

# 정확도 계산
accuracy_sm = (y_pred_class_sm == y_test).mean()
print(f"Statsmodels Logistic Regression Accuracy: {accuracy_sm:.4f}")
```

PyTorch와 `statsmodels`를 사용하여 각각 로지스틱 회귀 모델을 학습시키고, 두 모델의 성능을 비교할 수 있습니다. 
PyTorch는 더 복잡한 모델을 구현할 수 있는 유연성을 제공하는 반면, 
`statsmodels`는 통계적 모델링과 해석에 더 적합합니다.
