---
title: "Boostcamp AI Tech (Day 038)"
date: 2024-09-25
layout: post
tags: [Naver Boostcamp, daily report]
---
## 1. 강의

## 2. 피어세션
- 우리 실험을 개 잘못하고 있었다
- 데이터가 어떻게 되어있는지 봤어야했다. 분포... 
- 이미지 같은데 라벨 다른 거 지우기 프로그램 사용

## 3. 회고
- 우리 잘 헤어져요~!

## 4. 멘토링
- 랩업리포트 멘토님밖에 안 봄
- 나중에 포폴ㄷ에 쓸거면 잘 써라
- 왜했고 뭘했고 뭔 생각으로 이걸 했고 결과가 내 생각과 같았나 달랐나 왜 같고 달랐나 뭘생각했고 뭘 배웠는지 위주~
- 주석다는 습관, 불필요한건 x
- 주석없이도 코드 이해할 정도로 변수명, 함수명 길게 쓰는 게 굳
- 구현과 가져다쓰는걸(활용) 구분해서 말해주세요
- 걍 학교에서 과제한 거 좀 어려운 거 이력서에 써도 됨.
- 일단 다 적어라... 피드백러가 알아서 빼준다
- 팀은 흩어지는거 권장
- 시월에 밥 한 번 사줄게용!!!
- ResNet50이 성능이 잘 나올수가 있나요? 십 년 됐는데? ㅋㅋ... 추론능력, 내부 복잡성 많이 떨어지지 않나.
- 어떤 모델 해서 잘 안됐으면 이 모델을 훈련시킬 여느 테크닉이 부족했을 것임. 우리탓!
- 객체탐지의 욜로 계열 모델에서만 모자이크가 잘 되더라 => 모델마다 잘 치는 어그멘테이션이 다르다...
- 더 복잡한 모델일수록 더 많은 데이터가 필요하겠지?  viT등 트랜스포머 계열은 훨 더 많은 데이터가 필요할거고.
- 일단 우리 지금 모델이 너무 작다
- 고해상도 모델 활용, 증강은 GAN이나 생성모델 사용하든, 
- 어떤 어그멘테이션이 이 모델에 적합한지 아는 법 : 그 모델에 그 증강써서 피처맵을 얻은 후 투디멘젼... 저차원으로 프로젝션 시켜서 거기서 봤을 때 
- 트레인은 증강이미지, val은 원본이미지로 하잖아? 얘를 투디멘젼... 2차원 평면으로 보내면 아마 트레인일때랑 val일때 분포가 다를것임. 우린 이 파란색 분포를 데이터 확장시켜서 그 빨간 범위도 커버할 수 있도록 해야함. 증강의 목적~!
이미지 => 모델에 태워서 특징벡터 뽑고 이를 pca나 T SNE나 UMAP이나 ... 저차원으로 줄여서 봤을때 val이 잘 되고 있는가 보면 
아 우린 테스트 이미지도 라벨은 없지만 주어졌으니 val대신 테스트 데이터로 넣고 해서 하면 그 범위를 보고 위위처럼 하자.
각 모델에 맞는 어그멘테이션, 옵티마이저, 스케줄러 설정이 다름... 
- 최소한 viT나 MAE나 efficentNet 초기에 실험해봤어야함. 증강 이런 거 없이 자연빵으로 얼마나 나오는지 테스트 해봤어야 했다.
- 원래 실험이랑 이론이랑 다르다.. 옵티마이저는 많이 알고 많이 실험해봐야 안다... 
- 뭔 옵티마이저가 뭐가 부족해서 이렇게 나왓다. 근데 이 상황이 우리 상황과 같은지 알아야 한다.
ex) 임의로 데이터 샘플링 했을 때 이상한 거 뜨는구나 adam대신 radam을 뽑아 쓰는게 좋겟다...
- 어떤 상황에서 잘 쓰일 수 있는지만 옵티마이저 정리를 해봐라.
- 코드 개선하는 사람-> 뭘 주로 개선했나?, 데이터 다룬 사람-> 어떤 인사이트를 얻었나/어떤 이미지 어그멘테이션을 썼나 -> 좋은 인사이트를 얻어놓고 왜 아무 조치를 안했나...?, 옵티마이저 다룬 소윤이 헤헤-> 근데 이걸 가져와?ㅋㅋ, 데이터 다룬 사람2 어그멘테이션 등 엣지 추출 실패 n개 증강 반영 못 함-> 적용한 이미지만 썼어야 할 듯, 모델 다룬 사람 일단 코드짜고 -> 왜 그 모델들 선정했나요? 그 웹페이지에서 성능 좋다는 애 가져왔다 -> 당연히 대기업 코드가 우리가 짠 코드보다 훨 좋다 좋은 시도다~ 
- 실험을.. 한 개가 3시간이면... 2주니까 500개는 쌓였어야함
- 파일 사이즈 체크해서 같은 것만 제거했으면 됐을 듯. 완전 똑같은 이미지가 다른 라벨 들고 있으면.
- 수작업을 안 하면 좋지만, 수작업을 해야하는 순간... 수작업이 빠른 순간이 있음... 룰에 어긋나지 않으면 그냥 해도 된다
- 후에 성예닮 멘토님께 대학원 진학 생각있다, 이력서 여기요 하자!!!
- 면접 이야기를 해보자요
- 어그멘테이션 딱 하나 쓴다면? 생성형이요 -> 호오... 현실적으로 생각해주세요, 어파인 트랜스폼 -> 시야각을 바꾸는 거잖아 비율 달라지는 게 방해되지 않을까? -> 이미지 특성에 맞게 하이퍼파라미터를 조절해서 최대한 덜 비율 망치게 어그멘테이션하면 되지 않을까 -> 좋겠네요!, 블러 -> 블러는 픽셀이 뭉개지는거라. 해당영역 정보가 사라지는 것. 복원 어려움. 빛번짐같이. 아마 색으로만 보일텐데 이건 디테일한 학습이 어려울듯. 동영상에선 성능 좋을 것이다
- 마스킹, 드롭아웃, 컷아웃, 믹스업 등 이미지의 일부를 변환하거나 없애는 걸 많이 활용함. -> 좀 가려진채로 정보를 알아내는게 어려운 추론 능력이므로 이렇게 훈련 시키면 좋다. 
- data2vec : 이미지든 음성이든 영상이든 마스킹이 짱이다 논문

- 우리 잘 헤어져요... 다른 멘토에게도 무제한 질문하기!!!
