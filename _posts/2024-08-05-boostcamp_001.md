---
title: "Boostcamp AI Tech (Day 001)"
date: 2024-08-05
layout: post
tags: [Naver Boostcamp, daily report]
---
## 새롭게 알게된 점
`view`와 `reshape`는 텐서를 재구조화하는데 사용되지만, 둘 사이에 중요한 차이가 있다. `view`는 연속된 메모리에서만 동작하며, 텐서의 데이터를 재배치하지 않는다. 반면, `reshape`는 필요할 경우 데이터를 재배치하여 새로운 형태로 텐서를 만든다.

따라서, `view`를 사용하려고 할 때 오류가 발생하는 이유는 텐서의 데이터가 연속적이지 않기 때문이다. 이 경우 `reshape`를 사용해야 한다. 예를 들어, `reshape`를 사용하여 텐서를 재구조화할 수 있다.

```python
e = d.reshape(1, -1)
print('e =', e)
```

만약 `reshape`도 제대로 동작하지 않는다면, 다음과 같이 `contiguous` 메소드를 사용하여 텐서를 연속적인 메모리 블록으로 변환한 후 `view`를 사용할 수 있다.

```python
d_contiguous = d.contiguous()
e = d_contiguous.view(1, -1)
print('e =', e)
```

`reshape`는 기본적으로 `contiguous`와 유사한 작업을 수행하므로, 아래 방법이 작동해야 한다.

```python
e = d.reshape(1, -1)
print('e =', e)
```

summary
- `view`는 텐서의 데이터가 연속적인 경우에만 사용 가능.
- `reshape`는 데이터가 연속적이지 않더라도 새로운 형태로 텐서를 재구조화할 수 있음.
- `contiguous`는 텐서를 연속적인 메모리 블록으로 변환.

## 1. 강의

# **PyTorch Intro**

### 1) 실습 개요
이번 실습에서는 Tensor의 의미에 대한 이해를 바탕으로 차원별 Tensor의 모습과 코드 표현을 탐구해 봅니다.

### 2) 실습 진행 목적 및 배경
PyTorch와 AI 분야에서 Tensor는 필수적인 개념 중 하나입니다. 실습을 통해 PyTorch Tensor의 코드 표현을 확인하고 차원별 Tensor의 모습과 쓰임새를 이해하고자 합니다.

### 3) 실습 수행으로 얻어갈 수 있는 역량
- 실습을 통해 Tensor의 PyTorch 코드 표현을 사용할 수 있다.

### 4) 실습 핵심 내용
&nbsp;&nbsp; 4.2 Tensor의 여러가지 표현<br>

### 5) Required Package
```bash
pip install torch
```

# **Data type & Basic Functions**

### 1) 실습 개요
이번 실습에서는 Tensor의 다양한 데이터 타입과 타입 캐스팅 방법에 대해 학습합니다. 또한 Tensor를 다루는 함수와 메서드들을 사용해보며 각각의 역할을 익혀봅니다.

### 2) 실습 진행 목적 및 배경
PyTorch에서 데이터 타입을 이해  
AI 학습 및 활용 시 알맞은 데이터 타입을 사용하지 않으면 의도와는 다른 결과물을 얻을 수 있다.  
Tensor를 다루는 여러 함수와 메서드들을 배움으로써 AI 개발에 유용하게 사용할 수 있다.

### 3) 실습 내용
&nbsp;&nbsp; 1.1 PyTorch의 데이터 타입<br>
&nbsp;&nbsp; 1.2 타입 캐스팅<br>
&nbsp;&nbsp; 2.1 Tensor의 요소를 반환하거나 계산하는 함수<br>
&nbsp;&nbsp; 2.2 Tensor의 특성을 확인하는 메서드<br>

### 5) Required Package
```bash
pip install torch
```

```python
import torch

# 데이터 타입 예제
t = torch.FloatTensor([1.0, 2.0, 3.0])
print(t)
print(t.dtype)  # 출력: torch.float32

# 타입 캐스팅 예제
t_int = t.to(torch.int32)
print(t_int)
print(t_int.dtype)  # 출력: torch.int32
```

# **Creating Tensors**

### 1) 실습 개요
이번 실습에서는 Tensor의 다양한 생성 방법과 초기화에 대한 이해를 바탕으로 PyTorch에서 실제로 Tensor를 생성하고 초기화하는 여러 방법들을 수행

### 2) 실습 진행 목적 및 배경
PyTorch에서 Tensor는 필수적으로 알아야 하는 요소 중 하나.  
AI의 학습은 주로 병렬 처리에 용이한 GPU에서 이루어지기 때문에 PyTorch에서 GPU 환경을 인식하고 Tensor를 GPU에 할당하는 방법을 아는 것이 중요하다.  
실습의 목적은 PyTorch에서 Tensor를 생성 및 초기화하는 다양한 방법을 이해하고 Tensor를 GPU, CPU 디바이스에 할당하거나 변환하는 방법을 이해하는 것이다.

### 3) 실습 내용
&nbsp;&nbsp; 1.1 특정한 값으로 초기화된 Tensor 생성<br>
&nbsp;&nbsp; 1.2 특정한 값으로 초기화된 Tensor 변환<br>
&nbsp;&nbsp; 1.3 난수로 초기화된 Tensor 생성<br>
&nbsp;&nbsp; 1.4 지정된 범위 내에서 초기화된 Tensor 생성<br>
&nbsp;&nbsp; 1.5 초기화 되지 않은 Tensor 생성<br>
&nbsp;&nbsp; 1.6 list, Numpy 데이터로부터 Tensor 생성<br>
&nbsp;&nbsp; 1.7 CPU Tensor 생성<br>
&nbsp;&nbsp; 1.8 Tensor 복제<br>
&nbsp;&nbsp; 1.9 CUDA Tensor 생성과 변환<br>

### 5) Required Package
```bash
pip install torch
```

```python
import torch

# 0으로 초기화된 Tensor 생성
t_zeros = torch.zeros([1, 10, 100])
print(t_zeros)

# 난수로 초기화된 Tensor 생성
t_rand = torch.randn([2, 3])
print(t_rand)

# CUDA Tensor 생성
if torch.cuda.is_available():
    t_cuda = torch.randn([2, 3], device='cuda')
    print(t_cuda)
```

# **Manipulation of Tensors**

### 1) 실습 개요
이번 실습에서는 텐서의 인덱싱과 슬라이싱, 모양 변경에 대한 이해를 바탕으로 PyTorch에서 텐서를 조작

### 2) 실습 진행 목적 및 배경
AI 모델을 설계할 때 Tensor에서 원하는 요소들만 선택하여 가져오거나 Tensor의 모양을 변경하는 Tensor의 조작은 필수 요소 중 하나이다.  
PyTorch에서 Tensor를 다루는 방법을 익히고 AI 모델을 설계, 개발할 때 알맞게 활용하기 위함입니다.

### 3) 실습 내용
&nbsp;&nbsp; 1.1 Tensor의 indexing & slicing<br>
&nbsp;&nbsp; 2.1 view() 메서드를 활용한 Tensor의 모양변경<br>
&nbsp;&nbsp; 2.2 flatten() 함수를 활용한 Tensor의 평탄화<br>
&nbsp;&nbsp; 2.3 reshape() 메서드를 활용한 Tensor의 모양변경<br>
&nbsp;&nbsp; 2.4 transpose() 메서드를 활용한 Tensor의 모양변경<br>
&nbsp;&nbsp; 2.5 squeeze() 함수를 활용한 Tensor의 차원 축소<br>
&nbsp;&nbsp; 2.6 unsqueeze() 함수를 활용한 Tensor의 차원 확장<br>
&nbsp;&nbsp; 2.7 stack() 함수를 활용한 Tensor들 간의 결합<br>

### 5) Required Package
```bash
pip install torch
```

```python
import torch

# Tensor 생성
t = torch.randn(3, 4, 5)

# 인덱싱과 슬라이싱
print(t[0])        # 첫 번째 행
print(t[:, 1])     # 모든 행의 두 번째 열

# view 메서드를 활용한 Tensor의 모양변경
t_view = t.view(3, 20)
print(t_view.shape)

# flatten 함수를 활용한 Tensor의 평탄화
t_flatten = t.flatten()
print(t_flatten.shape)

# reshape() 메서드를 활용한 Tensor의 모양변경
t_reshape = t.reshape(5, 12)
print(t_reshape.shape)

# transpose() 메서드를 활용한 Tensor의 모양변경
t_transpose = t.transpose(0, 2)
print(t_transpose.shape)

# squeeze() 함수를 활용한 Tensor의 차원 축소
t_squeeze = torch.randn(1, 3, 4, 1)
print(t_squeeze.squeeze().shape)

# unsqueeze() 함수를 활용한 Tensor의 차원 확장
t_unsqueeze = t_squeeze.unsqueeze(0)
print(t_unsqueeze.shape)

# stack() 함수를 활용한 Tensor들 간의 결합
t1 = torch.randn(2, 3)
t2 = torch.randn(2, 3)
t_stack = torch.stack((t1, t2), dim=0)
print(t_stack.shape)
```

<br><br>
		
## 2. Peer session

* Ice breaking
* Peer session 계획서 작성
<br><br>
	
## 3. Daily report 환경 세팅

* jekyll을 이용해 theme 설치 & 적용
* 상단 icon image file 생성 & 적용
* categories 변경, About.md 수정
<br><br>

## 4. 회고

* 행복하다. 첫날이라서 피곤하지만 내일은 오늘보다 더 알차게 공부하고싶다!
<br><br>

<br><br>
